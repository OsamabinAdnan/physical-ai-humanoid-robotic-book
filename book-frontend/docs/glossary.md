---
sidebar_position: 21
title: Glossary of Terms
---

# Glossary of Terms

This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook.

## A

**Action Space**: The set of possible actions that an agent can take in an environment.

**Affordance**: The possibility of an action on an object or environment; what an object or environment offers, furnishes, or provides to an agent.

**AI (Artificial Intelligence)**: The simulation of human intelligence processes by machines, especially computer systems.

**Articulated Robot**: A robot with rotary joints (e.g., a leg or arm), allowing for complex movement patterns.

## B

**Behavior Tree**: A hierarchical model used to create complex behaviors from simple tasks, commonly used in robotics and game AI.

**Bipedal**: Having two feet or legs; refers to robots that walk on two legs like humans.

## C

**Cognitive Architecture**: The mental system that enables an agent to perceive, reason, learn, and act in an environment.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world.

**Control Theory**: An engineering and mathematics field dealing with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback.

## D

**Deep Learning**: A subset of machine learning based on artificial neural networks with representation learning.

**Degrees of Freedom (DOF)**: The number of independent movements a mechanical system can make.

**Dexterity**: The skill in performing tasks, especially with hands; in robotics, the ability to perform complex manipulation tasks.

## E

**Embodied AI**: Artificial intelligence that involves a physical body interacting with the real world.

**End Effector**: The device at the end of a robotic arm designed to interact with the environment.

**Episodic Memory**: Memory of autobiographical events (times, places, associated emotions, etc.) that can be explicitly stated.

## F

**Forward Kinematics**: The use of joint parameters to compute the Cartesian position and orientation of the end effector.

**Fiducial Marker**: A visual marker that can be detected and tracked by computer vision algorithms.

## G

**Gazebo**: An open-source 3D robotics simulator that allows accurate simulation of robots and environments.

**Generalization**: The ability of a model to adapt properly to new, previously unseen data drawn from the same distribution as the training data.

## H

**Haptic Feedback**: The use of touch feedback to communicate with users through vibrations, motion, or force.

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots.

**Hybrid Systems**: Systems that exhibit both continuous and discrete dynamic behavior.

## I

**Inverse Kinematics**: The mathematical process of calculating joint parameters from the Cartesian position and orientation of the end effector.

**Isaac ROS**: NVIDIA's hardware-accelerated perception and navigation libraries for robotics.

**Isaac Sim**: NVIDIA's robotics simulation application based on NVIDIA Omniverse.

## K

**Kinematics**: The study of motion without considering the forces that cause the motion.

**Kinesthetic Teaching**: A method of teaching robots by physically guiding them through motions.

## L

**Large Language Model (LLM)**: A language model with many parameters that is trained on vast amounts of text data.

**Latent Space**: A lower-dimensional space that captures the essential features of high-dimensional data.

**Legged Locomotion**: The ability of robots with legs to move and navigate through environments.

## M

**Manipulation**: The ability to handle or control objects using robotic end effectors.

**Middleware**: Software that provides common services and capabilities to applications beyond what's offered by the operating system.

**Motion Planning**: The computational problem of automatically planning a path for a robot to follow.

## N

**Nav2**: The ROS 2 navigation stack for mobile robots.

**Neural Radiance Fields (NeRF)**: A method for synthesizing novel views of complex scenes using neural networks.

**NVIDIA Isaacâ„¢**: A robotics platform that includes simulation, navigation, and perception tools.

## P

**Perception**: The ability of a robot to interpret sensory data from its environment.

**Physical AI**: The field of artificial intelligence focused on robots and physical systems interacting with the real world.

**PID Controller**: A control loop mechanism employing feedback that is widely used in industrial control systems.

**Point Cloud**: A collection of data points in a coordinate system, typically used to represent 3D shapes.

**Prismatic Joint**: A joint that provides linear sliding movement between two bodies.

## R

**Reinforcement Learning**: A type of machine learning where agents learn to take actions in an environment to maximize cumulative reward.

**Revolute Joint**: A joint that provides rotation between two bodies.

**Robot Operating System (ROS)**: Flexible framework for writing robot software.

**ROS 2**: The second generation of the Robot Operating System with improved security, real-time capabilities, and multi-robot support.

**Rigid Body**: An idealization of a solid body in which deformation is neglected.

**ROS Package**: A container for organizing ROS functionality, including nodes, libraries, and configuration files.

## S

**Sensor Fusion**: The process of combining data from multiple sensors to improve the accuracy and reliability of information.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Social Robotics**: The study and development of robots that can interact with humans in a socially acceptable way.

**State Space**: The set of all possible configurations of a system.

**Supervised Learning**: A type of machine learning where the model is trained on labeled data.

**System Integration**: The process of bringing together the component subsystems into one system and ensuring that they function together.

## T

**Task Planning**: The process of decomposing high-level goals into executable sequences of actions.

**Teleoperation**: The remote operation of a robot by a human operator.

**Trajectory Planning**: The process of creating a path for a robot to follow in terms of position, velocity, and acceleration over time.

**Transformer Architecture**: A deep learning model that uses attention mechanisms to weigh the importance of input data.

## U

**URDF (Unified Robot Description Format)**: An XML format for representing a robot model in ROS.

**Uncanny Valley**: The hypothesis that human replicas that appear almost, but not exactly, like real human beings cause a feeling of eeriness and revulsion among human observers.

**Unstructured Environment**: An environment where the layout, objects, and conditions are not predetermined or controlled.

## V

**VLA (Vision-Language-Action)**: A paradigm that combines visual perception, language understanding, and physical action in robotic systems.

**VSLAM (Visual SLAM)**: SLAM using visual sensors as the primary source of information.

**Vision System**: A system that uses cameras and computer vision algorithms to perceive and interpret visual information.

## W

**Whisper**: OpenAI's automatic speech recognition system.

**Whole-Body Control**: A control approach that coordinates all available degrees of freedom in a robot simultaneously.

**Workspace**: The space within which a robot manipulator can operate.

## X, Y, Z

**Zero Moment Point (ZMP)**: A criterion for static and dynamic stability of legged robots.

**ZMP Controller**: A controller that maintains the robot's center of mass within the support polygon to ensure stability.